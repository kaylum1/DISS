# server/Security_scans/Passive_Vulnerability_Cross_Reference_Scanner.py

import requests
import argparse
import json
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import re

# API Endpoint for vulnerability checks (using National Vulnerability Database)
NVD_API_URL = "https://services.nvd.nist.gov/rest/json/cves/1.0?keyword="

# Common headers and libraries to detect
TECHNOLOGY_PATTERNS = {
    "Server": r"Server: (.+)",
    "X-Powered-By": r"X-Powered-By: (.+)",
    "jQuery": r"jquery-(\d+\.\d+\.\d+).min.js",
    "Bootstrap": r"bootstrap-(\d+\.\d+\.\d+).min.js",
    "WordPress": r"/wp-content/",
    "Drupal": r"/sites/all/",
    "Joomla": r"/media/system/js/",
}

# Score deductions per vulnerability severity
SCORE_DEDUCTIONS = {
    "critical": 4,
    "high": 3,
    "medium": 2,
    "low": 1
}

def get_headers(url):
    """
    Fetches HTTP headers from the target website.
    """
    try:
        response = requests.head(url, timeout=10, allow_redirects=True)
        return response.headers
    except requests.RequestException as e:
        print(f"[Error] Could not retrieve headers for {url}: {e}")
        return {}

def get_page_content(url):
    """
    Fetches the HTML content of the target webpage.
    """
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        return response.text
    except requests.RequestException as e:
        print(f"[Error] Could not retrieve page content for {url}: {e}")
        return None

def detect_technologies(url, headers, html):
    """
    Scans headers and HTML to detect server type, CMS, and libraries.
    Returns a dictionary of detected technologies.
    """
    detected = {}

    # Check HTTP headers
    for key, pattern in TECHNOLOGY_PATTERNS.items():
        for header, value in headers.items():
            match = re.search(pattern, f"{header}: {value}", re.IGNORECASE)
            if match:
                detected[key] = match.group(1)
    # Check HTML for JavaScript libraries
    soup = BeautifulSoup(html, "html.parser")
    for script in soup.find_all("script", src=True):
        script_src = script["src"]
        for tech, pattern in TECHNOLOGY_PATTERNS.items():
            match = re.search(pattern, script_src, re.IGNORECASE)
            if match:
                detected[tech] = match.group(1)
    return detected

def check_vulnerabilities(technologies):
    """
    Queries the NVD API for vulnerabilities related to detected technologies.
    Returns a tuple: (security score, list of detail strings)
    """
    base_score = 10
    details = []
    vulnerabilities = {}

    for tech, version in technologies.items():
        query = f"{tech} {version}" if version else tech
        print(f"üîç Checking for vulnerabilities related to: {query}")
        try:
            response = requests.get(NVD_API_URL + query, timeout=10)
            try:
                data = response.json()
            except ValueError:
                print(f"[Error] Could not decode JSON for query '{query}'. Response text: {response.text}")
                continue

            if "result" in data and "CVE_Items" in data["result"]:
                cve_items = data["result"]["CVE_Items"]
                if cve_items:
                    vulnerabilities[tech] = cve_items[:3]  # Limit to top 3 results
                    for cve in cve_items:
                        severity = cve.get("impact", {}).get("baseMetricV3", {}).get("cvssV3", {}).get("baseSeverity", "unknown").lower()
                        score_deduction = SCORE_DEDUCTIONS.get(severity, 1)
                        base_score -= score_deduction
                        cve_id = cve["cve"]["CVE_data_meta"]["ID"]
                        details.append(f"‚ùå {tech}: {cve_id} ({severity.capitalize()})")
        except requests.RequestException as e:
            print(f"[Error] Could not retrieve CVE data for query '{query}': {e}")

    # Ensure score stays within 1-10 range.
    final_score = max(1, min(10, base_score))

    if final_score == 10:
        details.append("‚úÖ No known vulnerabilities detected for identified technologies.")
    elif final_score < 5:
        details.append("‚ö†Ô∏è High risk: The site has technologies with known security vulnerabilities!")
    else:
        details.append("‚ö†Ô∏è Moderate risk: Some detected technologies have security issues.")

    return final_score, details

def get_base_url(url):
    """
    Extracts the base URL from a given URL, ensuring it has https://.
    """
    if "://" not in url:
        url = "https://" + url  # Assume HTTPS by default
    parsed = urlparse(url)
    return f"{parsed.scheme}://{parsed.netloc}"

def analyze_vulnerabilities(url):
    """
    Wrapper function to perform the vulnerability scan.
    Returns a tuple: (final_score, details_string)
    """
    base_url = get_base_url(url)
    headers = get_headers(base_url)
    html = get_page_content(base_url)
    if not headers or not html:
        return 1, "‚ùå Could not retrieve necessary data."
    
    detected_tech = detect_technologies(base_url, headers, html)
    if not detected_tech:
        return 10, "No detectable technologies found. Likely minimal exposure."
    
    score, details_list = check_vulnerabilities(detected_tech)
    details_str = "; ".join(details_list)
    return score, details_str

def main():
    parser = argparse.ArgumentParser(description="Passive Vulnerability Database Cross-Reference Scanner")
    parser.add_argument("-u", "--url", required=True, help="Target website URL")
    args = parser.parse_args()

    base_url = get_base_url(args.url)
    print(f"üîç Scanning for known vulnerabilities on: {base_url}\n")

    headers = get_headers(base_url)
    html = get_page_content(base_url)

    if not headers or not html:
        print("‚ùå Failed to retrieve necessary data.")
        return

    detected_tech = detect_technologies(base_url, headers, html)
    print(f"üîé Detected Technologies: {detected_tech}")

    if not detected_tech:
        print("‚úÖ No detectable technologies found. Likely minimal exposure.")
        return

    score, details = check_vulnerabilities(detected_tech)

    print("\n--- üîç Vulnerability Report ---")
    for line in details:
        print(f" - {line}")

    print("\n--- üî¢ Security Score ---")
    print(f"Security Score: {score} / 10")
    if score < 5:
        print("‚ö†Ô∏è The website has severe security vulnerabilities!")
    elif score < 8:
        print("‚ö†Ô∏è The website has some security risks. Fixing recommended.")
    else:
        print("‚úÖ No major security vulnerabilities detected.")

if __name__ == "__main__":
    main()
